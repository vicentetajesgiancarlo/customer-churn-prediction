{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte Técnico: Predicción de Abandono de Clientes (Churn)\n",
    "\n",
    "Este documento detalla el proceso, las decisiones técnicas y los resultados obtenidos en el proyecto de predicción de churn para una empresa de telecomunicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo del Proyecto\n",
    "El objetivo principal fue desarrollar un modelo capaz de identificar proactivamente a los clientes con alta probabilidad de cancelar su servicio, permitiendo así implementar estrategias de retención efectivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metodología Paso a Paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploración de Datos \n",
    "Se analizaron las distribuciones de las variables y su relación con la cancelación (Variable Objetivo - Churn):\n",
    "- **Variables Numéricas**: Se observó que los clientes con mayor **MonthlyCharges** (cargos mensuales) y menor **tenure** (antigüedad) tienen una mayor tendencia a abandonar la empresa.\n",
    "- **Variables Categóricas**: Se identificó que tipos de contrato específicos (Mes a Mes) y métodos de pago (Check electrónico) están fuertemente asociados con el churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocesamiento de Datos\n",
    "Para preparar los datos para los modelos, realizamos:\n",
    "1. **Limpieza**: Eliminación de identificadores irrelevantes (`customerID`).\n",
    "2. **Tratamiento de Nulos**: Se imputaron valores faltantes en `TotalCharges` usando la mediana.\n",
    "3. **Codificación**:\n",
    "   - **Binaria**: Variables con dos categorías se convirtieron en 0 y 1.\n",
    "   - **Nuevas Categorías**: Categorías múltiples se transformaron en columnas booleanas independientes.\n",
    "4. **Estandarización**: Se utilizó `StandardScaler` para que variables como `tenure` y `MonthlyCharges` estuvieran en la misma escala, evitando sesgos en el modelo.\n",
    "5. **División**: Se dividió el set en 80% entrenamiento y 20% prueba, manteniendo la proporción original de churn (26%) en ambos para garantizar una evaluación justa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelos Utilizados y Justificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Regresión Logística (Modelo Base)\n",
    "- **¿Qué es?**: Un modelo estadístico que predice la probabilidad de una variable binaria (0 o 1).\n",
    "- **Justificación**: Es simple, rápido de entrenar y altamente interpretable (permite ver qué variables pesan más). Sirve como punto de comparación.\n",
    "- **Configuración**: Se usó `class_weight='balanced'` para compensar que hay menos casos de churn que de retención."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: XGBoost (Optimizado)\n",
    "- **¿Qué es?**: Un algoritmo de *Gradient Boosting* basado en árboles de decisión que construye modelos en serie, donde cada nuevo árbol corrige los errores de los anteriores.\n",
    "- **Justificación**: Es uno de los algoritmos más potentes actualmente debido a su manejo de relaciones no lineales y su resistencia al sobreajuste (*overfitting*).\n",
    "- **Optimización**: Se realizó una búsqueda aleatoria de hiperparámetros (`RandomizedSearchCV`) con validación cruzada para encontrar la mejor combinación de profundidad de árboles y velocidad de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resultados y Comparativa\n",
    "\n",
    "Se evaluaron los modelos principalmente mediante el **ROC-AUC** (capacidad de distinguir entre clases) y el **Recall** (capacidad de detectar a los que sí se van).\n",
    "\n",
    "| Métrica | Regresión Logística | XGBoost |\n",
    "| :--- | :---: | :---: |\n",
    "| **ROC-AUC** | 0.8417 | **0.8468** |\n",
    "| **Recall (Churn)** | 0.78 | **0.81** |\n",
    "| **Precisión (Churn)** | 0.51 | **0.52** |\n",
    "| **Accuracy** | 0.74 | **0.75** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones de Resultados:\n",
    "- **XGBoost** superó ligeramente a la Regresión Logística en todas las métricas, confirmando ser el modelo más robusto.\n",
    "- **Estrategia de Trade-off (Precisión vs. Recall)**: \n",
    "    - Hemos priorizado intencionalmente el **Recall (0.81)** sobre la precisión.\n",
    "    - **Razón de Negocio**: En la predicción de churn, el costo de omitir a un cliente que realmente se va (Falso Negativo) es significativamente mayor que el costo de contactar a un cliente que no tenía intención de irse (Falso Positivo).\n",
    "    - Con una precisión del **52%**, sabemos que aproximadamente la mitad de nuestras alertas serán \"falsas alarmas\", pero esto nos permite capturar el **81% de los abandonos reales**, maximizando la retención de ingresos.\n",
    "- Ambos modelos muestran un excelente **ROC-AUC (0.84+)**, lo que indica una alta capacidad para distinguir entre clientes que cancelan y los que permanecen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
